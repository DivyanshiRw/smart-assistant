# Smart Research Assistant ğŸ“„
This is a Streamlit + FastAPI based LLM-powered assistant that can:

* Automatically summarize any uploaded document.
* Answer deep, contextual questions with justifications.
* Challenge users with reasoning-based questions and evaluate their responses.

---
## ğŸ”§ Features

- âœ… Upload PDF/TXT documents
- âœ… Auto-summarization
- âœ… Ask document-based questions and receive justified answers
- âœ… Challenge mode: Get logical questions â†’ Submit answers â†’ Receive feedback with correct responses
- âœ… Highlight supporting document snippet
- ğŸ§  Uses [Groq](https://groq.com/) API to run powerful open-source LLMs like LLaMA 3 and Mixtral

---

## ğŸ“ Project Structure

```
smart-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”‚ â”œâ”€â”€ qa.py                # QA logic (ask anything)
â”‚ â”‚ â”‚ â”œâ”€â”€ challenge.py         # Challenge mode (Q&A evaluation)
â”‚ â”‚ â”‚ â”œâ”€â”€ parser.py            # Document parsing (PDF/TXT)
â”‚ â”‚ â”‚ â”œâ”€â”€ summarizer.py        # Auto-summary
| | |â”€â”€ routes.py              # API endpoints
â”‚ â”‚ â”œâ”€â”€ main.py                # FastAPI app instance
â”‚ â”‚ â”œâ”€â”€ state.py               # Global document memory
â”‚â”€â”€ .env                       # Environment file (Groq API key) - > âš ï¸ `.env` is excluded from Git.
â”œâ”€â”€ requirements.txt
|
â”œâ”€â”€ frontend/
| |â”€â”€ requirements.txt
â”‚ â”œâ”€â”€ streamlit_app.py # Streamlit UI
â”‚
â”œâ”€â”€ Sample Outputs
|
â”œâ”€â”€ venv
|
â””â”€â”€ README.md 
```

---

## ğŸ“¦ Setup & Installation

### 1. ğŸ”‘ Get a Groq API Key

1. Go to: [https://console.groq.com/keys](https://console.groq.com/keys)
2. Create an account (if needed)
3. Generate an API Key
4. Create a file named `.env` in the root of your project:
```
GROQ_API_KEY=your_key_here
```


---

### 2. ğŸ“¦ Install Dependencies

Use **Python 3.9+**. Recommended to create a virtual environment:

Open new terminal on your editor.

```bash
# Create and activate venv (Windows)
python -m venv venv
& .\venv\Scripts\Activate.ps1

# OR on Mac/Linux
python3 -m venv venv
source venv/bin/activate

# Then install:
pip install -r requirements.txt

```


### 3. ğŸš€ Run the Backend
```bash
cd backend
uvicorn app.main:app --reload
```
API will be live at: http://127.0.0.1:8000

### 4. ğŸ–¥ï¸ Run the Frontend
```bash
cd frontend
streamlit run streamlit_app.py
```
Open the UI at: http://localhost:8501


## ğŸ’¡ Usage Instructions
### Upload & Summarize
* Upload a PDF or TXT file.
* The assistant summarizes and shows text preview.

### Ask Anything
* Type your question â†’ Get a clear answer with justification.
* Supporting snippet shown directly.

### Challenge Me
* Click "Generate Questions" â†’ Answer them â†’ Submit.
* System evaluates your logic and gives:
Feedback,
 Ideal answer

### ğŸŒŸ Bonus Feature:
ğŸ“Œ Answer Highlighting: Shows document snippet used for answer



## ğŸ§ª Models Used
Via Groq API:

* llama3-8b-8192
* mixtral-8x7b-instruct

## ğŸ§  Tech Stack
* Backend: FastAPI    ![FastAPI](https://img.shields.io/badge/Backend-FastAPI-teal)
* Frontend: Streamlit ![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-orange)
* LLM API: Groq       ![Groq](https://img.shields.io/badge/LLM-Groq_LLaMA3-red)

---
# ğŸ“Œ Project Objective:
This project is built as part of a task designed to assess the ability to go beyond basic automation and demonstrate contextual understanding, logical reasoning, and applied GenAI capabilities.

### ğŸ¯ Objective:
The goal was to build an AI-powered assistant that is document-aware and capable of:

* Accurately answering free-form questions grounded in document content.
* Generating logical, inference-based questions from the document.
* Evaluating user-submitted answers with justifications from the source.
* Providing a concise summary upon upload.

### âœ… Functional Highlights:
* Ask Anything: Users can ask any question. The assistant finds the most relevant context and gives a precise answer with document-based justification.
* Challenge Me: The system generates 3 thought-provoking questions. It evaluates the user's answers, gives feedback, and shows the ideal response.
* Auto Summary: Displays a short summary (â‰¤150 words) as soon as a document is uploaded.
* Justified Responses: Every response is backed by a referenced snippet or paragraph.
* Answer Highlighting (Bonus Feature Implemented): Visually shows the document excerpt that the answer is based on.


### ğŸ–¼ Sample Outputs

Screenshots demonstrating key features (summary, QA, evaluation, etc.) are available in the [`Sample_Outputs/`](./Sample_Outputs) folder.


